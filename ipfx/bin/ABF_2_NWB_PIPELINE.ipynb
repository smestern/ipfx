{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ABF 2 NWB PIPELINE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N679irLgbkwH",
        "colab_type": "text"
      },
      "source": [
        "# Smestern ABF to Nwb conversion pipeline\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf3pvOZgb9GB",
        "colab_type": "text"
      },
      "source": [
        "This tutorial will show you how to convert ABF files to NWB files in a 'cell-dependant' manner. First, we have to install some dependencies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SacWJrOCPVMH",
        "colab_type": "code",
        "outputId": "7371f79b-f55f-4918-bf7d-de10e0d2911f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "!git clone https://github.com/smestern/ipfx.git\n",
        "!git clone https://github.com/smestern/example-abf-files.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ipfx'...\n",
            "remote: Enumerating objects: 81, done.\u001b[K\n",
            "remote: Counting objects: 100% (81/81), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 4998 (delta 34), reused 56 (delta 24), pack-reused 4917\u001b[K\n",
            "Receiving objects: 100% (4998/4998), 32.70 MiB | 38.53 MiB/s, done.\n",
            "Resolving deltas: 100% (3581/3581), done.\n",
            "Cloning into 'example-abf-files'...\n",
            "remote: Enumerating objects: 24, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 24 (delta 5), reused 21 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_NWkqZkQKv_",
        "colab_type": "code",
        "outputId": "2e267394-c779-4db0-8b99-b592d0b5e6a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!apt-get install -qq /content/ipfx\n",
        "!pip uninstall statsmodels -y\n",
        "!pip uninstall tables -y\n",
        "!pip install statsmodels==0.9.0\n",
        "!pip install tables==3.5.1\n",
        "!pip install /content/ipfx --log /content/log.txt\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Unsupported file /content/ipfx given on commandline\n",
            "Uninstalling statsmodels-0.10.2:\n",
            "  Successfully uninstalled statsmodels-0.10.2\n",
            "Uninstalling tables-3.4.4:\n",
            "  Successfully uninstalled tables-3.4.4\n",
            "Collecting statsmodels==0.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/d1/69ee7e757f657e7f527cbf500ec2d295396e5bcec873cf4eb68962c41024/statsmodels-0.9.0-cp36-cp36m-manylinux1_x86_64.whl (7.4MB)\n",
            "\u001b[K     |████████████████████████████████| 7.4MB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.9.0) (0.5.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.9.0) (0.25.3)\n",
            "Requirement already satisfied: numpy>=1.4 in /usr/local/lib/python3.6/dist-packages (from patsy->statsmodels==0.9.0) (1.17.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy->statsmodels==0.9.0) (1.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels==0.9.0) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->statsmodels==0.9.0) (2018.9)\n",
            "Installing collected packages: statsmodels\n",
            "Successfully installed statsmodels-0.9.0\n",
            "Collecting tables==3.5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/79/4e1301a87f3b7f27aa6c9cb1aeba4875ff3edb62a6fe3872dc8f04983db4/tables-3.5.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.1) (1.17.5)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.1) (2.7.1)\n",
            "Collecting mock>=2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.1) (1.12.0)\n",
            "Installing collected packages: mock, tables\n",
            "Successfully installed mock-3.0.5 tables-3.5.1\n",
            "Processing ./ipfx\n",
            "Requirement already satisfied: h5py>=2.3.1 in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (2.8.0)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (1.17.5)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (0.25.3)\n",
            "Requirement already satisfied: scipy>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (1.4.1)\n",
            "Collecting simplejson>=3.10.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/a7b98aa9256c8843f92878966dc3d8d914c14aad97e2c5ce4798d5743e07/simplejson-3.17.0.tar.gz (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (6.2.2)\n",
            "Collecting argschema\n",
            "  Downloading https://files.pythonhosted.org/packages/f0/ec/bd27b60a9fcbae7c56e40d87c268a58b75c83181779e78235b320462dba5/argschema-1.17.5-py2.py3-none-any.whl\n",
            "Collecting marshmallow==2.20.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e3/07/c7a12d21619abeedf5fca7381f4cf3fa798a26e8d92ad66bc73f5fc58fc1/marshmallow-2.20.5-py2.py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[?25hCollecting allensdk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/d4/121f315cea35e14325616a349324e84382dfa743d61f541f4a6b83782787/allensdk-1.3.2-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.3MB/s \n",
            "\u001b[?25hCollecting dictdiffer\n",
            "  Downloading https://files.pythonhosted.org/packages/97/92/350b6b6ec39c5f87d98d04c91a50c498518716a05368e6dea88b5c69b590/dictdiffer-0.8.1-py2.py3-none-any.whl\n",
            "Collecting hdmf==1.1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/6d/e5b89edf14db989c4846c42b0216d76491398bd442ba17483cd840cd5b68/hdmf-1.1.2-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.4MB/s \n",
            "\u001b[?25hCollecting pyabf==2.0.25\n",
            "  Downloading https://files.pythonhosted.org/packages/be/09/18ff09a3688b8fa42aebf9520cab080a5dd83aa0c168752f8ad333461ad4/pyabf-2.0.25.tar.gz\n",
            "Collecting pynwb==1.0.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/72/c709ff36701cd4791cb3e296df7421acbac11699406c331eb9f10c79289b/pynwb-1.0.2-py2.py3-none-any.whl (96kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 11.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from ipfx==0.1.0) (1.12.0)\n",
            "Collecting watchdog\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.8MB/s \n",
            "\u001b[?25hCollecting pg8000\n",
            "  Downloading https://files.pythonhosted.org/packages/16/32/ae895597e43bc968e0e3e63860e9932b851115457face0d06d7f451b71fc/pg8000-1.13.2-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->ipfx==0.1.0) (2.4.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->ipfx==0.1.0) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->ipfx==0.1.0) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->ipfx==0.1.0) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.17.0->ipfx==0.1.0) (2018.9)\n",
            "Collecting nest-asyncio==1.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/81/f3/e59eb5fa5c41c7e6ae9741ed18534dbfae15ad29040a3927396678934b28/nest_asyncio-1.2.0-py3-none-any.whl\n",
            "Requirement already satisfied: jinja2>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (2.10.3)\n",
            "Requirement already satisfied: future>=0.14.3 in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (0.16.0)\n",
            "Collecting simpleitk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d8/53338c34f71020725ffb3557846c80af96c29c03bc883551a2565aa68a7c/SimpleITK-1.2.4-cp36-cp36m-manylinux1_x86_64.whl (42.5MB)\n",
            "\u001b[K     |████████████████████████████████| 42.5MB 100kB/s \n",
            "\u001b[?25hCollecting pynrrd>=0.2.1\n",
            "  Downloading https://files.pythonhosted.org/packages/92/00/ef17d52fd125f357d7ead95e823091b2344194d34ce94e2fe839184f48e7/pynrrd-0.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tables==3.5.1 in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (3.5.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (0.9.0)\n",
            "Collecting glymur==0.8.19\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/f9/01b464dd2b312c1f9bec26f985f2d0a9eef1a7390e407588578cc135fde0/Glymur-0.8.19.tar.gz (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 39.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-image>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (0.16.2)\n",
            "Collecting psycopg2-binary>=2.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/c0/16303cef8d54fdcfae7be7880cf471f21449225687f61cc3be2a7ef4e6e5/psycopg2_binary-2.8.4-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: statsmodels==0.9.0 in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (0.9.0)\n",
            "Collecting scikit-build\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8a/b5/c6ca60421991c22e69b9a950b0d046e06d714f79f7071946ab885c7115fb/scikit_build-0.10.0-py2.py3-none-any.whl (66kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (2.21.0)\n",
            "Collecting aiohttp==3.6.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/39/7eb5f98d24904e0f6d3edb505d4aa60e3ef83c0a58d6fe18244a51757247/aiohttp-3.6.2-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 40.1MB/s \n",
            "\u001b[?25hCollecting requests-toolbelt\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: xarray in /usr/local/lib/python3.6/dist-packages (from allensdk->ipfx==0.1.0) (0.14.1)\n",
            "Collecting ruamel.yaml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fa/90/ecff85a2e9c497e2fa7142496e10233556b5137db5bd46f3f3b006935ca8/ruamel.yaml-0.16.5-py2.py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 55.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet in /usr/local/lib/python3.6/dist-packages (from pynwb==1.0.2->ipfx==0.1.0) (3.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.6/dist-packages (from pynwb==1.0.2->ipfx==0.1.0) (2.8)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from pynwb==1.0.2->ipfx==0.1.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from pynwb==1.0.2->ipfx==0.1.0) (1.24.3)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog->ipfx==0.1.0) (3.13)\n",
            "Collecting argh>=0.24.1\n",
            "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting scramp==1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/bb/ef/6bdba6756ba7ccb81187833504ebba0511af750a2d9beaa04e4b56c3974f/scramp-1.1.0-py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->ipfx==0.1.0) (42.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.7.3->allensdk->ipfx==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.1->allensdk->ipfx==0.1.0) (2.7.1)\n",
            "Requirement already satisfied: mock>=2.0 in /usr/local/lib/python3.6/dist-packages (from tables==3.5.1->allensdk->ipfx==0.1.0) (3.0.5)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->allensdk->ipfx==0.1.0) (2.4)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->allensdk->ipfx==0.1.0) (1.1.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.0->allensdk->ipfx==0.1.0) (2.4.1)\n",
            "Requirement already satisfied: patsy in /usr/local/lib/python3.6/dist-packages (from statsmodels==0.9.0->allensdk->ipfx==0.1.0) (0.5.1)\n",
            "Requirement already satisfied: wheel>=0.29.0 in /usr/local/lib/python3.6/dist-packages (from scikit-build->allensdk->ipfx==0.1.0) (0.33.6)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from scikit-build->allensdk->ipfx==0.1.0) (20.0)\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/06/5a/d423c846bb839105143d4cd90da19d0f3fc972c51be651f92ac419a20698/multidict-4.7.4-cp36-cp36m-manylinux1_x86_64.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 56.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp==3.6.2->allensdk->ipfx==0.1.0) (19.3.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 60.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp==3.6.2->allensdk->ipfx==0.1.0) (3.6.6)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting ruamel.yaml.clib>=0.1.2; platform_python_implementation == \"CPython\" and python_version < \"3.8\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/53/77/4bcd63f362bcb6c8f4f06253c11f9772f64189bf08cf3f40c5ccbda9e561/ruamel.yaml.clib-0.2.0-cp36-cp36m-manylinux1_x86_64.whl (548kB)\n",
            "\u001b[K     |████████████████████████████████| 552kB 58.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.0->allensdk->ipfx==0.1.0) (4.4.1)\n",
            "Building wheels for collected packages: ipfx, simplejson, pyabf, watchdog, glymur, pathtools, idna-ssl\n",
            "  Building wheel for ipfx (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipfx: filename=ipfx-0.1.0-py2.py3-none-any.whl size=14078210 sha256=0c39dad0fba732dc4e72a59d7e6ba12fd24920504c72b8a4205ae9fe524301fc\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_3huxcxa/wheels/dc/e2/3e/c10a6a5f38660c10e14677b0ced72b814121aed4e4a5f40d18\n",
            "  Building wheel for simplejson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simplejson: filename=simplejson-3.17.0-cp36-cp36m-linux_x86_64.whl size=114201 sha256=e947bfcccfe2ebb694dca8acfce3a62b4f86e6f52c0a7cf91389eb62a9584e69\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/c0/83/dcd0339abb2640544bb8e0938aab2d069cef55e5647ce6e097\n",
            "  Building wheel for pyabf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyabf: filename=pyabf-2.0.25-cp36-none-any.whl size=37531 sha256=61a30ca59abcd6eb8609d5a5b8a69b3d547ff7e1ede194de31e6ed4776701367\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/7a/3c/0ceb9ff71604f49500979e55dd70ba1c187560a1ba3d4f78c2\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=e7343cc20dec1a1ecd19186dd571c79a301021439bee0a8f36410f48cf126047\n",
            "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
            "  Building wheel for glymur (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for glymur: filename=Glymur-0.8.19-cp36-none-any.whl size=2721999 sha256=7f289f7873aebe40806b05f9b1b02c10f102ff7c60fd247f1fe5b8414bfd1685\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/c6/f6/918d148fb2aa6a13606af5475644e8116e9398485c36f0d995\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=faa4975a7485d2b75da30e0c695c923fe4aa6a180160823939c0e9ecabcad48e\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3163 sha256=5be9d5e7277143c99881594835abeee2d4ba286cccd6a6291a236dc6556c8dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "Successfully built ipfx simplejson pyabf watchdog glymur pathtools idna-ssl\n",
            "\u001b[31mERROR: allensdk 1.3.2 has requirement hdmf==1.0.2, but you'll have hdmf 1.1.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: allensdk 1.3.2 has requirement marshmallow==3.0.0rc6, but you'll have marshmallow 2.20.5 which is incompatible.\u001b[0m\n",
            "Installing collected packages: simplejson, marshmallow, argschema, nest-asyncio, ruamel.yaml.clib, ruamel.yaml, hdmf, simpleitk, pynwb, pynrrd, glymur, psycopg2-binary, scikit-build, idna-ssl, multidict, yarl, async-timeout, aiohttp, requests-toolbelt, allensdk, dictdiffer, pyabf, argh, pathtools, watchdog, scramp, pg8000, ipfx\n",
            "Successfully installed aiohttp-3.6.2 allensdk-1.3.2 argh-0.26.2 argschema-1.17.5 async-timeout-3.0.1 dictdiffer-0.8.1 glymur-0.8.19 hdmf-1.1.2 idna-ssl-1.1.0 ipfx-0.1.0 marshmallow-2.20.5 multidict-4.7.4 nest-asyncio-1.2.0 pathtools-0.1.2 pg8000-1.13.2 psycopg2-binary-2.8.4 pyabf-2.0.25 pynrrd-0.4.2 pynwb-1.0.2 requests-toolbelt-0.9.1 ruamel.yaml-0.16.5 ruamel.yaml.clib-0.2.0 scikit-build-0.10.0 scramp-1.1.0 simpleitk-1.2.4 simplejson-3.17.0 watchdog-0.9.0 yarl-1.4.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hn_vEhtOdEXT",
        "colab_type": "text"
      },
      "source": [
        "The above commands downloads a few example abf files to be used in this tutorial. Additionally, it downloads & installs my (slightly modified) version of Allen Institute's IPFX. This is the package utilized for conversion. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2sZ6V-aWuJ1",
        "colab_type": "text"
      },
      "source": [
        "## Step 1 Generate your JSON files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z2_yFofQdCRu",
        "colab_type": "text"
      },
      "source": [
        "IPFX's primary input files are javascript object notation (.json). For the specific process of converting ABF files into NWB to use with IPFX, we need to create / modify 3 JSON files:\n",
        "\n",
        "1.   mcc-settings.json\n",
        "2.   stimulus_ontology.json\n",
        "3.   conversion_input.json\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EubJNp1IfcZs",
        "colab_type": "text"
      },
      "source": [
        "### mcc-settings.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IcBQJuzfon6",
        "colab_type": "text"
      },
      "source": [
        "ABF's only provide a small amount of data regarding the experiments. As a result, some information needs to be extracted from the programs used to gather the data. Specifically, we need to pull information from 'multi-clamp commander' (mcc). This can be achieved using '[mcc_get_settings.py](https://github.com/smestern/ipfx/blob/master/ipfx/bin/mcc_get_settings.py)' from the ipfx package. (NOTE: if you attempt this, it requires a 32-bit installation of python)\n",
        "\n",
        "Ideally, this would be done at the time of the experiment. However, since these experiments were done in the past, we will have to compose this manually. I have generated this file on my lab computer using the '[mcc_get_settings.py](https://github.com/smestern/ipfx/blob/master/ipfx/bin/mcc_get_settings.py)' script. This is provided in the example data:\n",
        "\n",
        "Please see the documented example below: (terms are defined by the axon guide: [https://mdc.custhelp.com/euf/assets/content/Axon%20Guide%203rd%20edition.pdf](https://mdc.custhelp.com/euf/assets/content/Axon%20Guide%203rd%20edition.pdf))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U0YNz3LjTJ-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "{\n",
        "    \"00830749_1\": { //this section refers to the settings pulled from Multi-clamp commander\n",
        "        \"GetFastCompCap\": 7.385518412117431e-12, //These are auto calculated by MCC. The current value is about average for our experiments.\n",
        "        \"GetFastCompTau\": 9.270073064726603e-07, //These are auto calculated by MCC. The current value is about average for our experiments.\n",
        "        \"GetHolding\": -0.0699935033917427,\n",
        "        \"GetHoldingEnable\": false,\n",
        "        \"GetLeakSubEnable\": false,\n",
        "        \"GetLeakSubResist\": 10000000.0,\n",
        "        \"GetMeterIrmsEnable\": false,\n",
        "        \"GetMeterResistEnable\": false,\n",
        "        \"GetMode\": 0, //For most cases mode '0' = current clamp, mode '1' = voltage clamp. However this does not really matter as the ABF file contains this information\n",
        "        \"GetModeSwitchEnable\": false,\n",
        "        \"GetOscKillerEnable\": false,\n",
        "        \"GetOutputZeroEnable\": false,\n",
        "        \"GetPipetteOffset\": 35.03935899958014488, // for our data, the pipette offset hovers aproxiamtely around 30-40mV. This will vary depending on the lab. \n",
        "        \"GetPrimarySignal\": 0,\n",
        "        \"GetPrimarySignalGain\": 5.0, //this is experiment specific, for our 'NHP' recording, the current clamp gain was set to 5. \n",
        "        \"GetPrimarySignalHPF\": 0.0,\n",
        "        \"GetPrimarySignalLPF\": 1600.0,\n",
        "        \"GetPulseAmplitude\": 5.009999999776482582,\n",
        "        \"GetPulseDuration\": 0.009999999776482582,\n",
        "        \"GetRsCompBandwidth\": 1020.47998046875,\n",
        "        \"GetRsCompCorrection\": 0.0,\n",
        "        \"GetRsCompEnable\": false,\n",
        "        \"GetRsCompPrediction\": 0.0,\n",
        "        \"GetScopeSignalLPF\": 0.0,\n",
        "        \"GetSecondarySignal\": 1,\n",
        "        \"GetSecondarySignalGain\": 1.0,\n",
        "        \"GetSecondarySignalLPF\": 10000.0,\n",
        "        \"GetSlowCompCap\": 1.4285714538403438e-12, //These are auto calculated by MCC. The current value is about average for our experiments.\n",
        "        \"GetSlowCompTau\": 0.00010256410314468667, //These are auto calculated by MCC. The current value is about average for our experiments.\n",
        "        \"GetSlowCompTauX20Enable\": false,\n",
        "        \"GetWholeCellCompCap\": 3.300633377723017e-11,\n",
        "        \"GetWholeCellCompEnable\": false,\n",
        "        \"GetWholeCellCompResist\": 9997999.0,\n",
        "        \"GetZapDuration\": 0.0005000000237487257\n",
        "    },\n",
        "    \"ScaleFactors\": { //Refers to the scale applied to each stimulus.\n",
        "        \"C1NSD1SHORT\": 1.05,\n",
        "        \"IC1\": 5,\n",
        "        \"H:\\\\Monkey\\\\Ephys Protocols\\\\Monkey #3-4 Protocols\\\\Monkey Gap free\": 5, \\\\Enter your custom stimuli here\n",
        "        \"H:\\\\Monkey\\\\Ephys Protocols\\\\Monkey #3-4 Protocols\\\\Monkey_1000 ms step\": 5,\n",
        "        \"H:\\\\Monkey\\\\Ephys Protocols\\\\Monkey #3-4 Protocols\\\\Monkey_3 ms step\": 5,\n",
        "        \"LSFINEST\": 1.05,\n",
        "        \"SSFINEST\": 7,\n",
        "        \"TRIPPLE\": 7\n",
        "    },\n",
        "    \"timestamp\": \"2019-09-30T12:52:31.387664Z\",\n",
        "    \"uids\": {\n",
        "        \"IN0\": \"00830749_1\" //this links the 'input' (recording) electrode to the above MCC settings. \n",
        "        //In our case, the input electrode is labeled as IN0 in our ABF files. Therefore we must state the IN0 is the 'same' \n",
        "        // as 00830749_1\n",
        "    }\n",
        "}\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCO4EGpUn1GA",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://)### stimulus_ontology.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knj6pVZ0n5ma",
        "colab_type": "text"
      },
      "source": [
        " *(most)* ABF files have the stimulus waveform built into them, so no extra steps are needed to convert the stimulus into the NWB (this is done automatically).\n",
        "\n",
        "  However, stimulus ontology allows IPFX to link specific stimuli to the equivalent stimulus used at the Allen Institute. This is crucial when using the resulting NWB file with Allen institutes suite of tools.\n",
        "\n",
        "  To generate this file, the user should examine the stimulus of each ABF file [this can be done in *clampfit* by navigating to edit->Create Stimulus Waveform Signal; the stimulus protocol name can be found in file->properties]. The user should then find the matching stimuli from Allen institutes list of protocols (found here: [http://help.brain-map.org/download/attachments/8323525/CellTypes_Ephys_Overview.pdf?version=2&modificationDate=1508180425883&api=v2](http://help.brain-map.org/download/attachments/8323525/CellTypes_Ephys_Overview.pdf?version=2&modificationDate=1508180425883&api=v2). For example, our protocol \"Monkey_1000 ms step.pro\" matches Allen Institute's \"long pulse\": \n",
        "\n",
        "  **Monkey_1000 ms step.pro**\n",
        "  ![Monkey_1000 ms step.pro](https://i.imgur.com/YJ7WVQp.png)\n",
        "  **AI Long pulse**\n",
        "  ![LONG PULSE](https://i.imgur.com/pHBuy8W.png)\n",
        "\n",
        "\n",
        "Therefore I have to create an entry in 'stimulus_ontology.json' to link these two protocols:\n",
        "\n",
        "```\n",
        "[\n",
        "        [\n",
        "            \"code\", //The name of the protocol file used to create the ABF\n",
        "            \"Monkey_1000 ms step\"\n",
        "        ],\n",
        "        [\n",
        "            \"name\", //The name of the AI protocol you want to link it to\n",
        "            \"Long Square\"\n",
        "        ]\n",
        "]\n",
        "```\n",
        "\n",
        "The finished stimulus_ontology.json should be placed in /ipfx/ipfx/defaults/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BudbAFwosO-2",
        "colab_type": "text"
      },
      "source": [
        "### conversion_input.json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIsfi9GhsSf0",
        "colab_type": "text"
      },
      "source": [
        "This file is not needed for my script. However, if you are using an un-modified version of IPFX you will need to create an input.json for the x_to_NWB script."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1FX7YMEtiyo",
        "colab_type": "text"
      },
      "source": [
        "## Step 2 Organize your files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3WijOOUtvuZ",
        "colab_type": "text"
      },
      "source": [
        "For our experiments, each cell had several recordings (ABF files) associated with it. For my purposes, I needed each NWB file to represent a single cell. So, I sought to convert a collection of ABF files into a single NWB file. My script assumes that all ABF files found in a single folder represent a single cell (and subsequently builds an NWB file based on that folder). Therefore it is handy to organize your abf files like so:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRYFeCKKvFOX",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "|- Main folder\n",
        "|-|----Cell_1\n",
        "|-|----|---Cell_1_file1.abf\n",
        "|-|----|---Cell_1_file2.abf\n",
        "|-|----Cell_2\n",
        "|-|----|---Cell_2_file1.abf\n",
        "|-|----|---Cell_2_file2.abf\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rvd6-KwvjLg",
        "colab_type": "text"
      },
      "source": [
        "Note two things:\n",
        "\n",
        "1.   Each folder contains only abf files generated from a specific cell\n",
        "2.   Each folder is named after the specific cell.\n",
        "\n",
        "Now we can point the script at the 'main folder' and it will build two distinct NWB files\n",
        "\n",
        "\n",
        "1.   Cell_1.nwb (containing only:  Cell_1_file1.abf , Cell_1_file2.abf)\n",
        "2.   Cell_2.nwb (containing only:  Cell_1_file1.abf , Cell_1_file2.abf)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-ompQpKwfvP",
        "colab_type": "text"
      },
      "source": [
        "## Step 3 run run_NHP_to_nwb_conversion.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-qYpuwDwv6P",
        "colab_type": "text"
      },
      "source": [
        "run_NHP_to_nwb_conversion.py is a customized version of \"run_x_to_nwb_conversion.py,\" which more efficiently allows the user to batch convert abf files into NWB (based on the folder structure above).\n",
        "\n",
        "Below I will walk you through the code.\n",
        "\n",
        "To begin with, we need to define the main imports and primary function.\n",
        "These are unmodified from Allen Institute's \"run_x_to_nwb_conversion.py\":\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGwN53iVxa3l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!/bin/env python\n",
        "import shutil\n",
        "import os\n",
        "import argparse\n",
        "import logging\n",
        "log = logging.getLogger(__name__)\n",
        "import pyabf\n",
        "from ipfx.x_to_nwb.ABFConverter import ABFConverter\n",
        "from ipfx.x_to_nwb.DatConverter import DatConverter\n",
        "import numpy as np\n",
        "\n",
        "def convert(inFileOrFolder, overwrite=False, fileType=None, outputMetadata=False, outputFeedbackChannel=False, multipleGroupsPerFile=False, compression=True):\n",
        "    \"\"\"\n",
        "    Convert the given file to a NeuroDataWithoutBorders file using pynwb\n",
        "    Supported fileformats:\n",
        "        - ABF v2 files created by Clampex\n",
        "        - DAT files created by Patchmaster v2x90\n",
        "    :param inFileOrFolder: path to a file or folder\n",
        "    :param overwrite: overwrite output file, defaults to `False`\n",
        "    :param fileType: file type to be converted, must be passed iff `inFileOrFolder` refers to a folder\n",
        "    :param outputMetadata: output metadata of the file, helpful for debugging\n",
        "    :param outputFeedbackChannel: Output ADC data which stems from stimulus feedback channels (ignored for DAT files)\n",
        "    :param multipleGroupsPerFile: Write all Groups in the DAT file into one NWB\n",
        "                                  file. By default we create one NWB per Group (ignored for ABF files).\n",
        "    :param compression: Toggle compression for HDF5 datasets\n",
        "    :return: path of the created NWB file\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(inFileOrFolder):\n",
        "        raise ValueError(f\"The file {inFileOrFolder} does not exist.\")\n",
        "\n",
        "    if os.path.isfile(inFileOrFolder):\n",
        "        root, ext = os.path.splitext(inFileOrFolder)\n",
        "    if os.path.isdir(inFileOrFolder):\n",
        "        if not fileType:\n",
        "            raise ValueError(\"Missing fileType when passing a folder\")\n",
        "\n",
        "        inFileOrFolder = os.path.normpath(inFileOrFolder)\n",
        "        inFileOrFolder = os.path.realpath(inFileOrFolder)\n",
        "\n",
        "        ext = fileType\n",
        "        root = os.path.join(inFileOrFolder, \"..\",\n",
        "                            os.path.basename(inFileOrFolder))\n",
        "\n",
        "    outFile = root + \".nwb\"\n",
        "\n",
        "    if not outputMetadata and os.path.exists(outFile):\n",
        "        if overwrite:\n",
        "            os.remove(outFile)\n",
        "        else:\n",
        "            raise ValueError(f\"The output file {outFile} does already exist.\")\n",
        "\n",
        "    if ext == \".abf\":\n",
        "        if outputMetadata:\n",
        "            ABFConverter.outputMetadata(inFileOrFolder)\n",
        "        else:\n",
        "            ABFConverter(inFileOrFolder, outFile, outputFeedbackChannel=outputFeedbackChannel, compression=compression)\n",
        "    elif ext == \".dat\":\n",
        "        if outputMetadata:\n",
        "            DatConverter.outputMetadata(inFileOrFolder)\n",
        "        else:\n",
        "            DatConverter(inFileOrFolder, outFile, multipleGroupsPerFile=multipleGroupsPerFile, compression=compression)\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"The extension {ext} is currently not supported.\")\n",
        "\n",
        "    return outFile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHUKvvl4xlhm",
        "colab_type": "text"
      },
      "source": [
        "This defines the 'convert' function, which we call repeatedly in order to generate our NWB files.\n",
        "\n",
        "Next we will define the location of our files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUIxNkfbx72F",
        "colab_type": "code",
        "outputId": "adff9e77-61c7-4792-ef03-39d6d9d41900",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NHPPath = \"//content//example-abf-files//Example Files//\"\n",
        "os.chdir(\"//content//\")\n",
        "os.getcwd()\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "example-abf-files  ipfx  log.txt  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xqFA0ccyLUH",
        "colab_type": "text"
      },
      "source": [
        "This should point to your root folder, which contains all of the cell folders (as outlined above). In our case, we downloaded some example abfs earlier in this guide; therefore, we will point the path to the example folders. (if loaded in google 'colab' click the small arrow on the left to view the files).\n",
        "\n",
        "Now we are ready to convert:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFngfr9PytFe",
        "colab_type": "code",
        "outputId": "cbbc345b-ace5-41b9-9b05-47eb662628b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Converting\" + NHPPath)\n",
        "for r, celldir, f in os.walk(NHPPath): ##OS.walk steps through each folder and file in a given directory. This also searchs subfolders \n",
        "                                      ## for additonal folders\n",
        "              \n",
        "              for c in celldir: ##Walks through each folder (cell folder) in the root folder\n",
        "                   c = os.path.join(r, c) ##loads the subdirectory path\n",
        "                   \n",
        "                   shutil.copy(\"/content/example-abf-files/mcc-settings.json\",c) ### this path should point todays the mcc-settings.json we created earlier.\n",
        "                                                                                ## copys the mcc-settings.json into the cell folder for conversion. \n",
        "                                                                                ##otherwise throws an error\n",
        "                   print(f\"Converting {c}\")\n",
        "                   convert(c,\n",
        "                        overwrite=True,\n",
        "                        fileType='.abf',\n",
        "                        outputMetadata=False,\n",
        "                        outputFeedbackChannel=False,\n",
        "                        multipleGroupsPerFile=True,\n",
        "                        compression=True) ## this calls the conver command. It tells the command to look for all possible ABF files in the sub-folder."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Converting//content//example-abf-files//Example Files//\n",
            "Converting //content//example-abf-files//Example Files//Cell 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pynwb/file.py:619: UserWarning: Date is missing timezone information. Updating to local timezone.\n",
            "  warn(\"Date is missing timezone information. Updating to local timezone.\")\n",
            "/usr/local/lib/python3.6/dist-packages/ipfx/x_to_nwb/ABFConverter.py:467: UserWarning: Stored clamp mode 0 does not match requested clamp mode 1 of channel IN 0.\n",
            "  warnings.warn(f\"Stored clamp mode {settings['GetMode']} does not match requested \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Converting //content//example-abf-files//Example Files//Cell 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0bsdGO76PA8",
        "colab_type": "text"
      },
      "source": [
        "Despite the errors, the conversion was a success! As you can now see, the script copied mcc-settings.json into each folder. Additionally, two new NWB files exist in our root folder. These files are ready to be loaded into other programs!\n",
        "\n",
        "A quick look in HDFview reveals that everything is as it should be:\n",
        "![hdfview](https://i.imgur.com/kdIcmiY.png)"
      ]
    }
  ]
}